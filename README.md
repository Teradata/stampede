# Stampede README

Dean Wampler<br/>
[dean.wampler@thinkbiganalytics.com](mailto:dean.wampler@thinkbiganalytics.com)<br/>
November 21, 2012

Welcome to *Stampede*, the Hadoop-aware workflow tool that works as [Cthulhu](http://en.wikipedia.org/wiki/Cthulhu) intended for *nix systems, using `make` for dependency management, `bash` for scripting, and `cron` for scheduling.

## Installation

First, clone this repo or untar the distribution somewhere useful, e.g., `/usr/local/stampede`. Or, download and expand one of the releases.

Since *Stampede* uses `make` as part of its implementation, it's only appropriate that it uses `make` to run its tests and install itself:

    make install

If you **don't** have `syslog` on your system, run this command instead, which will skip the `syslog`-related tests:

    make install-no-syslog

2. Add `/usr/local/stampede/bin` (or whatever directory you used) to the `PATH` for any user who plans to use *Stampede*.
3. Copy `/usr/local/stampede/examples/stampederc` to one of the following locations, choosing one of the first two options appropriate for your operating system or for individual use, to the `$HOME` directory.
    * `/etc/stampederc`.
    * `/etc/sysconfig/stampede`.
    * `$HOME/.stampederc`.
4. Edit the properties in the copied `rc` file as appropriate for your environment.

## Usage

An individual workflow definition is called a *stampede*. 

For users who wish to customize all their stampedes, copy `/usr/local/stampede/examples/stampederc` to `$HOME/.stampederc` and edit to taste.

To create a stampede, run the following command:

    stampede create

It will prompt you for properties such as the name of the stampede and the project's working directory.

Edit the `.stampederc` and `makefile` created in the project directory to define your workflow. See the `$STAMPEDE_HOME/examples` for ideas. Note that `$STAMPEDE_HOME/bin` contains helper scripts to ease the development of workflows.

Once a stampede has been created, you can invoke it using this command:

    stampede [options] /path/to/makefile [make_targets]

For help on the `stampede` options:

    stampede --help

## Required Tools

* `bash` v3+ - Because OS X ships with an older bash version, all the scripts supplied are v3 compatible. You can use newer constructs if your version of bash supports them.
* GNU `make` v3.8+ - The template `makefile` generated by `stampede create` assumes GNU `make` syntax. You can adapt the `makefile` to any version of `make` you prefer.
* `cron` - If you plan to use `cron` for scheduling workflows.
* `syslog` - If you plan to use the *nix logging facility `syslog`. See also notes on building.
* *Hadoop* - Recent versions of Hadoop and other tools you might use, such as *Hive* and *Pig*, are required, but *Stampede* is mostly agnostic to versions. For each tool, Stampede relies on finding the tool in the `PATH` in order to determine installation directories, such as when it needs to find property definitions, invoke the tool, etc. If a tool isn't found on the `PATH`, *Stampede* will attempt to use the corresponding `$STAMPEDE_HOME` environment variable. If neither appropriate works, *Stampede* will exit with an error message.
 
## Supported Platforms

* **Linux** - All recent Linux distributions with `bash` v3+.
* **Mac OS X** - All recent OS X versions.

### Planned Support

Currently, `cygwin` and similar "Unix on Windows" toolkits are not supported, but only because we haven't tried them. We have tried to avoid any assumptions that would preclude this support. We welcome patches!

Note that as of this writing, support for running Hadoop in Windows environments was [just recently announced](https://www.hadooponazure.com/).

## Manifest

The top-level directory contains the following files, in addition to directories that will be described next:

* `README.md` - This file, as well as an HTML version of it.
* `LICENSE` - The copyright and license (Apache 2.0).
* `Makefile` - The `makefile` used to test and install *Stampede*.

### Bin Directory

*Stampede* supplies helper `bash` scripts in the `bin` directory. All the scripts that end with `.sh` are used internally by stampede. The files without this extension are user-callable utilities for building workflows.

Briefly, here are the utilities in the `bin` directory. All support a `--help` option for more information:

* `stampede` - The "stampede" (workflow) driver script. It can be invoked manually or by `cron`. It has several options to configure behavior. Run `stampede --help` for details.
* `dates` - Format dates and perform date arithmetic in a cross-platform way.
* `from-log-level` and `to-log-level` - Convert from a log-level string, e.g., `DEBUG` to the corresponding `syslog`-compatible number and back again.
* `log-file` - Return the name of the log file used by *stampede* or `SYSLOG` if `syslog` is being used.
* `send-email` - Use the *nux `mail` command (if configured) to send alerts.
* `stampede-log` - Write your own messages to the log file (or `syslog`) configured for *Stampede*.
* `success-or-failure` - Return one of two strings depending on a "success" flag.
* `true-or-false` - Return one of two strings depending on a whether a variable is empty or not.
* `to-seconds` - Return the number of seconds specified for an input number of seconds, minutes, or hours.
* `to-time-interval` - Like `to-seconds`, but returns a nicely formatted string.
* `try-for` - Repeated attempt an operation for a specified duration of time, until success or timeout.
* `try-for-or-die` - Like `try-for`, but fails the workflow on timeout.
* `try-until` - Like `try-for`, but tries until a user-specified timestamp.
* `try-until-or-die` - Like `try-for-or-die`, but tries until a user-specified timestamp.
* `waiting` - A `sleep(1)` wrapper with logging for use in loops, like the one in the `try-*` scripts.
* `ymd` - Return the year, month, and day for the workflow's start time, which defaults to today's date.
* `yesterday-ymd` - Return the year, month, and day for the day before the workflow's start time, i.e., yesterday's date, by default. For example, if you need to process yesterday's data, this is a convenient way to compute the correct date.

The following "helper" files are used by these scripts:

* `env.sh` - Defines global shell variables. Start here to find variables you can set in `rc` files to configure behavior.
* `common.sh` - Many "common" `bash` functions used in several scripts.
* `log.sh` - Support functions for logging.

### Custom and Contrib Directories

If you want to override the behavior of any particular script, drop a new version in the `custom` directory (or a subdirectory), which are added to the `PATH` first.

We intend for `contrib` to be a place where as-is, community-contributed tools will go. This directory and any subdirectories will also be added to the path, after `custom` and `bin`.

### Example Directory

The `example` directory contains several example *stampedes* that you can adapt for your purposes as well as a sample configuration file.

* `Makefile` - A sample `makefile`.
* `crontab` - A sample `crontab` file.
* `stampederc` - A sample file that overrides environment variable definitions to customize the environment or a particular project. See `bin/env.sh` for recommendations on where to install one or more of these `rc` files and for the complete list of variables available.
* `hadoop-example` - A small example using a typical Hadoop job.
* `pig-example` - A small example using a typical Pig job.
* `hive-example` - A small example using a typical Hive job.
* `big-example` - A larger, more realistic example of a workflow joining several different tools and steps.
 
### Test Directory

Tests of *Stampede* itself are in the `test` directory.


## TODO

* Copyright notices.
* Fill in examples.
* Installer.
* Create project support.
* Test email support.
* Test all the stampede CLI options.
* man pages

## Notes

* Supporting both Linux and Mac "date" commands added a lot of complication to the code. 